{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Final_Project_Naive_Architecture",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e8c8c4e8fb34a3ea4f3fc6784ed3b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_594ff0fe9262401c9c449409323ee7df",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c90c03828e7e4e84b925ce69455ba1c2",
              "IPY_MODEL_6c2d32d1d04d4ffb8f105c99d8082b52"
            ]
          }
        },
        "594ff0fe9262401c9c449409323ee7df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c90c03828e7e4e84b925ce69455ba1c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_903247fca64448349759f4c45922fbf5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_566f30688f0744e6be659e11be9e1903"
          }
        },
        "6c2d32d1d04d4ffb8f105c99d8082b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_59a21d03354a490191c5864b119ae19a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 119MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba5322e59d504817aa7bf78efbb0ac12"
          }
        },
        "903247fca64448349759f4c45922fbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "566f30688f0744e6be659e11be9e1903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59a21d03354a490191c5864b119ae19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba5322e59d504817aa7bf78efbb0ac12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EladGold/Emotion_Detection/blob/main/Final_Project_Naive_Architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na50xQmukMLh",
        "outputId": "32d1b3c8-8806-4b0a-fe47-2156b5423461"
      },
      "source": [
        "!pip install wandb --upgrade\r\n",
        "!pip install hiddenlayer --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/6b/4aacb6a29a52c2b2c27afe8ece383d0235a2ac8ec96b7257486f4e4328ea/wandb-0.10.20-py2.py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 18.7MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 41.5MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/74/59016eecaefa52443cd69cbb50e01851fa8bf3d9526771e2fae60ac6270c/sentry_sdk-0.20.3-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (53.0.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=3b2decd914df87777bd1e9d1326e507d6f3eeffb6a4b6ea6d90c5403ac30d362\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=e12b694cc5e8b2f7388f44eb91869a4c8e7b276097f985539a1e60d9a81fcea3\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: subprocess32, configparser, smmap, gitdb, GitPython, shortuuid, sentry-sdk, pathtools, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 sentry-sdk-0.20.3 shortuuid-1.0.1 smmap-3.0.5 subprocess32-3.5.4 wandb-0.10.20\n",
            "Collecting hiddenlayer\n",
            "  Downloading https://files.pythonhosted.org/packages/64/f8/ea51d02695a4dc397f3b2487fae462cd3f2ce707c54250e0fdfaec2ff92e/hiddenlayer-0.3-py3-none-any.whl\n",
            "Installing collected packages: hiddenlayer\n",
            "Successfully installed hiddenlayer-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivXk3SJoIHan"
      },
      "source": [
        "# Importing relevant Libraries\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torch.nn.functional as F\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import time\r\n",
        "import os\r\n",
        "import wandb\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRAH9q6RyrDC"
      },
      "source": [
        "# Choose GPU if available, else CPU\r\n",
        "if torch.cuda.is_available():\r\n",
        "    proc = torch.device('cuda')\r\n",
        "else:\r\n",
        "    proc = torch.device('cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4LHDMoES_4p",
        "outputId": "709dfa84-8e8f-46e2-a9f9-0d8a64417041"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "!pip install -q kaggle\r\n",
        "!pip install -q kaggle-cli\r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "# !cp \"/gdrive/MyDrive/FinalProject/kaggle.json\" ~/.kaggle/\r\n",
        "!cp \"/content/drive/MyDrive/FinalProject/kaggle.json\" ~/.kaggle/\r\n",
        "\r\n",
        "!cat ~/.kaggle/kaggle.json \r\n",
        "!chmod 600 ~/.kaggle/kaggle.json\r\n",
        "# For competition datasets\r\n",
        "!kaggle datasets download -d astraszab/facial-expression-dataset-image-folders-fer2013"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2MB 36.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 43.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 57.5MB/s \n",
            "\u001b[?25h  Building wheel for kaggle-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lxml (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for lxml\u001b[0m\n",
            "\u001b[?25h  Building wheel for PrettyTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "    Running setup.py install for lxml ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-acs_omli/lxml/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-acs_omli/lxml/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-bxjpmprz/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n",
            "{\"username\":\"eladgold\",\"key\":\"289c3ed2467eb873ab76ec0bad2e9361\"}Downloading facial-expression-dataset-image-folders-fer2013.zip to /content\n",
            " 65% 42.0M/65.1M [00:00<00:00, 108MB/s] \n",
            "100% 65.1M/65.1M [00:00<00:00, 165MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUij77F6Z2_f",
        "outputId": "537425a0-5b59-40ba-e500-680884e89646"
      },
      "source": [
        "# Complete path to storage location of the .zip file of data\r\n",
        "zip_path = '../content/drive/MyDrive/facial-expression-dataset-image-folders-fer2013.zip'\r\n",
        "# Check current directory (be sure you're in the directory where Colab operates: '/content')\r\n",
        "os.getcwd()\r\n",
        "# Copy the .zip file into the present directory\r\n",
        "!cp '{zip_path}' .\r\n",
        "# Unzip quietly \r\n",
        "data = !unzip -q 'facial-expression-dataset-image-folders-fer2013.zip'\r\n",
        "# View the unzipped contents in the virtual machine\r\n",
        "os.listdir()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '../content/drive/MyDrive/facial-expression-dataset-image-folders-fer2013.zip': No such file or directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'data',\n",
              " 'drive',\n",
              " 'facial-expression-dataset-image-folders-fer2013.zip',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUyeqf7XcY15",
        "outputId": "ccc5764e-80bc-4873-c650-7c3b3d3c2259"
      },
      "source": [
        "data_dir = '../content/data'\r\n",
        "\r\n",
        "train = data_dir + '/train'                           # Contains training images\r\n",
        "test = data_dir + '/test'                           # Contains test images\r\n",
        "\r\n",
        "val = data_dir + \"/val\"                               # Contains validation images\r\n",
        "print(os.listdir(data_dir))\r\n",
        "classes = os.listdir(train)\r\n",
        "print(classes)\r\n",
        "# /content/data/train/0\r\n",
        "train_0 = '../content/data/train/0'\r\n",
        "train_1 = '../content/data/train/1'\r\n",
        "train_2 = '../content/data/train/2'\r\n",
        "train_3 = '../content/data/train/3'\r\n",
        "train_4 = '../content/data/train/4'\r\n",
        "train_5 = '../content/data/train/5'\r\n",
        "train_6 = '../content/data/train/6'\r\n",
        "\r\n",
        "paths = [train_0, train_1, train_2 ,train_3 ,train_4 ,train_5 ,train_6]\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['val', 'test', 'train']\n",
            "['4', '3', '2', '5', '1', '0', '6']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-H18WNf9oAJ",
        "outputId": "e9f61ea8-43a0-4c54-a41c-4f20e3f5c75c"
      },
      "source": [
        "def countSamples (path):\r\n",
        "  file_count = 0\r\n",
        "  for _, dirs, files in os.walk(path):\r\n",
        "      file_count += len(files) \r\n",
        "  return file_count\r\n",
        "\r\n",
        "def getWeights (paths):\r\n",
        "  weights = []\r\n",
        "  for path in paths:\r\n",
        "    weights.append(1./countSamples(path))\r\n",
        "  return weights\r\n",
        "\r\n",
        "weights = getWeights (paths)\r\n",
        "# weights = [0.14, 0.14, 0.14, 0.14, 0.14, 0.14, 0.14]\r\n",
        "print (weights)\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00025031289111389235, 0.0022935779816513763, 0.000244081034903588, 0.0001386001386001386, 0.00020703933747412008, 0.000315357931251971, 0.0002014098690835851]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMP_mgIIdqiX"
      },
      "source": [
        "transform = transforms.Compose(\r\n",
        "        [\r\n",
        "            # transforms.RandomResizedCrop(224),\r\n",
        "            transforms.ToTensor(),\r\n",
        "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\r\n",
        "        ]\r\n",
        "    )\r\n",
        "\r\n",
        "# transform2 = transforms.Compose(\r\n",
        "#         [\r\n",
        "#             transforms.RandomHorizontalFlip(p = 0.5),\r\n",
        "#             transforms.ToTensor(),\r\n",
        "#             transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\r\n",
        "#         ]\r\n",
        "#     )\r\n",
        "# transform3 = transforms.Compose(\r\n",
        "#         [\r\n",
        "#             transforms.RandomAffine(20),\r\n",
        "#             transforms.ToTensor(),\r\n",
        "#             transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\r\n",
        "#         ]\r\n",
        "#     )\r\n",
        "# transform4 = transforms.Compose(\r\n",
        "#         [\r\n",
        "#             transforms.RandomRotation(30),\r\n",
        "#             transforms.ToTensor(),\r\n",
        "#             transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\r\n",
        "#         ]\r\n",
        "#     )\r\n",
        "\r\n",
        "# transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\r\n",
        "train_data = torchvision.datasets.ImageFolder(train, transform)\r\n",
        "\r\n",
        "for i in range(5):\r\n",
        "  train_data = torchvision.datasets.ImageFolder(train, transform)\r\n",
        "  # train_data += torchvision.datasets.ImageFolder(train_1, transform2)\r\n",
        "  # train_data += torchvision.datasets.ImageFolder(train_1, transform3)\r\n",
        "  # train_data += torchvision.datasets.ImageFolder(train_1, transform4)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "validation_data = torchvision.datasets.ImageFolder(val, transform)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-IIbjKzJ_21",
        "outputId": "13178ff8-fa45-403e-8c47-06edb9c78c3f"
      },
      "source": [
        "train_data[0][1]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoG7CU_jANS0"
      },
      "source": [
        "samples_weight = []\r\n",
        "for i in range(len(train_data)):\r\n",
        "  samples_weight.append(weights[train_data[i][1]])\r\n",
        "# print (samples_weight.shape)\r\n",
        "# samples_weight = torch.from_numpy(samples_weight)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQoYOV0eKS-s",
        "outputId": "e0fbcfa6-9dce-4493-a9dc-80ab5c2ae788"
      },
      "source": [
        "print (len(samples_weight))\r\n",
        "samples_weight = torch.tensor(samples_weight)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVfVmCMelguI",
        "outputId": "7f11962f-65b4-4d90-c53e-035dbf52ced4"
      },
      "source": [
        "print(len(train_data),len(validation_data))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28709 3589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGumtBQAl79z",
        "outputId": "19fd6a65-6220-4fb2-9793-6693baee0bcc"
      },
      "source": [
        "print(train_data[0][0].shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 48, 48])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_nMONDqp6u1"
      },
      "source": [
        "# Use dataloaders for train and test (batch size is batchSize)\r\n",
        "batchSize = 64\r\n",
        "sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(samples_weight))\r\n",
        "\r\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batchSize,\r\n",
        "                                           sampler = sampler)\r\n",
        "\r\n",
        "testloader = torch.utils.data.DataLoader(validation_data, batch_size=batchSize,\r\n",
        "                                         shuffle=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edMWLbl-GMM8"
      },
      "source": [
        "\r\n",
        "# for i, data in enumerate(trainloader, 0):\r\n",
        "#   print (data[1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "xPV6RZxi6649"
      },
      "source": [
        "#@title \r\n",
        "class EmotionDetect (nn.Module):\r\n",
        "\r\n",
        "\r\n",
        "#initialize the Neural network build. Expanding network\r\n",
        "    def __init__(self, external_model = None):\r\n",
        "        super(EmotionDetect, self).__init__()\r\n",
        "        if external_model is None:\r\n",
        "          external_model = torchvision.models.resnet50(pretrained= True)\r\n",
        "        self.features = nn.Sequential(*list(external_model.children())[:-3])\r\n",
        "        for i,p in enumerate(self.features.parameters()):\r\n",
        "          p.requires_grad = False\r\n",
        "\r\n",
        "\r\n",
        "        self.conv1 = nn.Conv2d(3, 64, 5)\r\n",
        "        self.batch1 = nn.BatchNorm2d(64)\r\n",
        "        self.conv2 = nn.Conv2d(64, 128, 5)\r\n",
        "        self.batch2 = nn.BatchNorm2d(128)\r\n",
        "        self.conv3 = nn.Conv2d(128, 256, 5)\r\n",
        "\r\n",
        "\r\n",
        "        \r\n",
        "        self.fc1 = nn.Linear(16384, 4096)\r\n",
        "        self.fc2 = nn.Linear(4096, 858)\r\n",
        "        self.fc3 = nn.Linear(858, 70) \r\n",
        "        self.fc4 = nn.Linear(70, 7)\r\n",
        "\r\n",
        "        self.dropout = nn.Dropout(0.4)\r\n",
        "        self.dropout2 = nn.Dropout(0.2)\r\n",
        "\r\n",
        "# The Forward propagation function for CNNFMnist\r\n",
        "    def forward(self, x):\r\n",
        "\r\n",
        "        x = self.conv1(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\r\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\r\n",
        "\r\n",
        "\r\n",
        "        x = torch.flatten(x, start_dim=1)\r\n",
        "\r\n",
        "        x = self.fc1(x)\r\n",
        "        x = self.dropout2(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = F.relu(self.fc3(x))\r\n",
        "        h = x\r\n",
        "        x = self.fc4(x)\r\n",
        "\r\n",
        "        return h,x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw-_ncazyQDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "6e8c8c4e8fb34a3ea4f3fc6784ed3b56",
            "594ff0fe9262401c9c449409323ee7df",
            "c90c03828e7e4e84b925ce69455ba1c2",
            "6c2d32d1d04d4ffb8f105c99d8082b52",
            "903247fca64448349759f4c45922fbf5",
            "566f30688f0744e6be659e11be9e1903",
            "59a21d03354a490191c5864b119ae19a",
            "ba5322e59d504817aa7bf78efbb0ac12"
          ]
        },
        "outputId": "aebb0ecc-3948-4ed9-b116-49059be1ffa8"
      },
      "source": [
        "# Initialize a new network\r\n",
        "net = EmotionDetect().to(proc)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# define loss function\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# define the optimizer\r\n",
        "\r\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\r\n",
        "\r\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=0.002)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e8c8c4e8fb34a3ea4f3fc6784ed3b56",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "zFD5ZB25K9vy",
        "outputId": "6949d2fd-ff62-4f7f-bf42-3151191edf28"
      },
      "source": [
        "# 1. Start a new run\r\n",
        "wandb.init(project=\"final_proj\", entity=\"eladg\")\r\n",
        "\r\n",
        "# 2. Save model inputs and hyperparameters\r\n",
        "config = wandb.config\r\n",
        "config.learning_rate = 0.001\r\n",
        "\r\n",
        "# 3. Log gradients and model parameters\r\n",
        "wandb.watch(net)    \r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.20<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">firm-thunder-27</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/eladg/final_proj\" target=\"_blank\">https://wandb.ai/eladg/final_proj</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/eladg/final_proj/runs/2y80kfra\" target=\"_blank\">https://wandb.ai/eladg/final_proj/runs/2y80kfra</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210301_160511-2y80kfra</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<wandb.wandb_torch.TorchGraph at 0x7f3f5e1205d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av8R6xtYyV20"
      },
      "source": [
        "# A function that trains the NN with the GPU\r\n",
        "# params epochs - number of epochs to train for\r\n",
        "# returns the loss history of the train and test data\r\n",
        "def trainingLoop (epochs):  \r\n",
        "  loss_history_train = []\r\n",
        "  running_loss_epoch = 0\r\n",
        "  loss_history_test = []\r\n",
        "  start_time = time.time()\r\n",
        "\r\n",
        "  for epoch in range(epochs):  \r\n",
        "\r\n",
        "      epoch_time = time.time()\r\n",
        "      running_loss = 0.0\r\n",
        "      for i, data in enumerate(trainloader, 0):\r\n",
        "\r\n",
        "          # get the inputs\r\n",
        "          inputs, labels = data\r\n",
        "          \r\n",
        "          inputs = inputs.to(proc)\r\n",
        "          labels = labels.to(proc) \r\n",
        "\r\n",
        "\r\n",
        "          # zero the parameter gradients\r\n",
        "          optimizer.zero_grad()\r\n",
        "\r\n",
        "          # forward + backward + optimize\r\n",
        "          outputs1, outputs2 = net(inputs)\r\n",
        "          loss = criterion(outputs2, labels)\r\n",
        "          loss.backward()\r\n",
        "          optimizer.step()\r\n",
        "\r\n",
        "          # print statistics\r\n",
        "          running_loss += loss.item()\r\n",
        "          running_loss_epoch += loss.item()\r\n",
        "          if (i+1) % 500 == 0:    \r\n",
        "              print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 500))\r\n",
        "              running_loss = 0.0\r\n",
        "\r\n",
        "      # Appending the loss per epoch for the train and test data to the history arrays\r\n",
        "      loss_history_train.append(running_loss_epoch/len(trainloader))\r\n",
        "      test_res = (testNET())\r\n",
        "      loss_history_test.append(test_res)\r\n",
        "      wandb.log({\"batchSize\": batchSize, \"loss\": running_loss_epoch/len(trainloader),\r\n",
        "                 \"testAcc\": test_res, \"time per epoch\": (time.time() - epoch_time)})\r\n",
        "      running_loss_epoch = 0\r\n",
        "      print(\"It took %s seconds for the epoch to run\" % (time.time() - epoch_time))\r\n",
        "      # 4. Log metrics to visualize performance\r\n",
        "\r\n",
        "  print('Finished Training')\r\n",
        "  print(\"It took %s seconds for the training to run\" % (time.time() - start_time))\r\n",
        "  return loss_history_train, loss_history_test"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA-O2IuAJU5a"
      },
      "source": [
        "# A function that checks the test accuracy of the NN \r\n",
        "def testNET ():\r\n",
        "  correct = 0\r\n",
        "  total = 0\r\n",
        "  running_loss = 0.0\r\n",
        "  with torch.no_grad():\r\n",
        "      for data in testloader:\r\n",
        "          images, labels = data\r\n",
        "          images = images.to(proc) \r\n",
        "          labels = labels.to(proc) \r\n",
        "          \r\n",
        "\r\n",
        "          outputs = net(images)\r\n",
        "          loss = criterion(outputs[1], labels)\r\n",
        "          running_loss += loss.item()\r\n",
        "          _, predicted = torch.max(outputs[1].data, 1)\r\n",
        "          total += labels.size(0)\r\n",
        "          correct += (predicted == labels).sum().item()\r\n",
        "\r\n",
        "  print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\r\n",
        "  wandb.log({\"correctnessPercent\": (100.0 * correct / total)})\r\n",
        "  return running_loss/len(testloader)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDrtoJE4zHlw",
        "outputId": "6ecb6967-51e8-4918-fa48-b2762c22a852"
      },
      "source": [
        "epochs = 20\r\n",
        "loss_history_train, loss_history_test = trainingLoop(epochs)\r\n",
        "\r\n",
        "plt.plot(range(epochs) , loss_history_train, 'blue')\r\n",
        "plt.plot(range(epochs) ,loss_history_test, 'red')\r\n",
        "plt.title(\"Loss Over Epochs\")\r\n",
        "plt.xlabel(\"Epochs\")\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.legend(['Training Loss', 'Test Loss']);\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 8 %\n",
            "It took 35.68516993522644 seconds for the epoch to run\n",
            "Accuracy of the network on the test images: 18 %\n",
            "It took 35.598899364471436 seconds for the epoch to run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd7keqcYBskG"
      },
      "source": [
        "import hiddenlayer as hl\r\n",
        "from google.colab import files\r\n",
        "hl.build_graph(net, torch.zeros([64, 3, 48, 48]).to(proc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8qb3JWu8AOI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}